{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "layout: post\n",
    "toc: true\n",
    "categories: [Big Idea5]\n",
    "title: 5.3 Computing Bias\n",
    "description: Big Idea 5.3\n",
    "type: ccc\n",
    "comments: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌 Popcorn Hacks - Computing Bias\n",
    "\n",
    "## 🤔 **Popcorn Hack #1**  \n",
    "**Question:** What is an example of Explicit Data?  \n",
    "\n",
    "**Options:**  \n",
    "- A) Netflix recommends shows based on your viewing history.  \n",
    "- B) You provide your name, age, and preferences when creating a Netflix account.  \n",
    "- C) Netflix tracks the time you spend watching certain genres.  \n",
    "\n",
    "**✅ Answer:**  \n",
    "**B) You provide your name, age, and preferences when creating a Netflix account.**  \n",
    "This is **explicit data** because the user directly provides this information.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🤔 **Popcorn Hack #2**  \n",
    "**Question:** What is an example of Data Bias?  \n",
    "\n",
    "**Options:**  \n",
    "- A) A hiring algorithm favors male candidates because the training data contains a disproportionate number of male resumes.  \n",
    "- B) A system is trained on a dataset where certain groups, such as people with darker skin tones, are underrepresented.  \n",
    "- C) A researcher intentionally selects data that supports their own beliefs about the impact of screen time on grades.  \n",
    "\n",
    "**✅ Answer:**  \n",
    "**B) A system is trained on a dataset where certain groups, such as people with darker skin tones, are underrepresented.**  \n",
    "This is **data bias** because the data itself is incomplete and does not reflect the full diversity of the population.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🤔 **Popcorn Hack #3**  \n",
    "**Question:** What is an example of Unintentional Bias?  \n",
    "\n",
    "**Example:** A facial recognition algorithm works better for lighter-skinned individuals because the training dataset mainly consists of images of people with lighter skin tones.  \n",
    "\n",
    "**✅ Answer:**  \n",
    "This is an example of **Unintentional Bias** because the developers did not deliberately exclude certain groups — the bias emerged from an unbalanced dataset. 🍪🍪  \n",
    "\n",
    "---\n",
    "\n",
    "## Homework Hack\n",
    "\n",
    "## ✍️ **Short-Answer Question**  \n",
    "**Explain the difference between implicit and explicit data. Provide an example of each.**  \n",
    "\n",
    "**Answer:**  \n",
    "**Explicit data** is information that is directly provided by the user. It includes personal details or preferences that the user inputs manually.  \n",
    "**Example:** When creating a Netflix account, you provide your name, age, and preferred genres — this is explicit data because it is directly given by the user.  \n",
    "**Implicit data** is information inferred from a user’s actions or behavior rather than directly provided.  \n",
    "**Example:** Netflix tracking your viewing history and recommending shows based on your past activity is implicit data because it is gathered from your behavior rather than direct input.  \n",
    "\n",
    "\n",
    "## 📝 **Lesson Notes:**\n",
    "- The blog explains **computing bias** and how algorithms can create or reinforce bias through flawed data, design, or unintended consequences.  \n",
    "- It covers **three types of bias**:\n",
    "  - **Algorithmic Bias** – Bias from a flawed or incomplete algorithm.  \n",
    "  - **Data Bias** – Bias caused by unrepresentative or erroneous data.  \n",
    "  - **Cognitive Bias** – Bias introduced by the researcher's or developer's own assumptions.  \n",
    "- The blog also explains **explicit vs implicit data**:\n",
    "  - **Explicit Data** – Directly provided by the user (e.g., name, preferences).  \n",
    "  - **Implicit Data** – Inferred from user behavior (e.g., viewing history).  \n",
    "- The section on **Intentional vs Unintentional Bias** highlights that even if bias is not deliberate, it can still lead to unfair outcomes.  \n",
    "- The **Mitigation Strategies** section outlines how to reduce bias during:\n",
    "  - **Pre-processing** – Clean and diversify training data.  \n",
    "  - **In-processing** – Use balanced datasets and synthetic samples.  \n",
    "  - **Post-processing** – Monitor performance and adjust for fairness.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
